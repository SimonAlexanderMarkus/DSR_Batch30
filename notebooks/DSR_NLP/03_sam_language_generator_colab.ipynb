{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f96c36-1268-462d-8cb5-a395108f6f9e",
   "metadata": {},
   "source": [
    "# Language Generation with Various Neural Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f46a6f-8640-4728-a41b-b94a2c584e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 08:32:55.412845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:32:55.412869: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448fdf2-3bb9-4dd5-a838-b003220ecdc1",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b727cd-a7d3-4240-a70b-957f2280f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15381618-1b38-40b0-8dcf-1b34e3fa12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw_dir = \"../../data/raw/SciFi_Stories_Text/\"\n",
    "dataset_raw_path = dataset_raw_dir + \"internet_archive_scifi_v3.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82935eb-8a9c-42a1-88b1-df4391042195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e54b25e-8736-4d88-aba0-87133e55b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internet_archive_scifi_v3.txt\n"
     ]
    }
   ],
   "source": [
    "!ls $dataset_raw_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a6457-47aa-45c0-a01c-e422a00b1452",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55554c8a-e6f1-44d1-8fdb-ba8b8de3b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = \"test_1\"\n",
    "\n",
    "batch_size = 1024\n",
    "seed = 42\n",
    "\n",
    "vocabulary_size = 10_000\n",
    "\n",
    "embedding_sizes = [16, 32, 64, 128]\n",
    "sequence_lengths = [16, 32, 64, 128]\n",
    "\n",
    "hidden_layer_neurons = [[16, 32, 64, 128], [16, 32, 64, 128, 256]]\n",
    "hidden_layer_activations = [\"sigmoid\", \"relu\", \"tanh\"]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4656b767-8332-4695-8b9e-891d407d1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 08:33:08.526761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 08:33:08.527139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-14 08:33:08.527494: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-14 08:33:08.527921: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocessing.text_dataset_from_directory(\n",
    "    dataset_raw_dir,\n",
    "    labels=None,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91681dde-d2e8-49e8-911c-044bb24830a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 08:33:16.392638: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 420938160 exceeds 10% of free system memory.\n",
      "2022-05-14 08:33:16.392975: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 631407240 exceeds 10% of free system memory.\n",
      "2022-05-14 08:33:17.275882: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 210469080 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "encoder = layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "\n",
    "encoder.adapt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d98d44f-89f9-4926-97a6-9322a17541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3006371f-fae7-49fd-95bf-50e0ab9e25e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['', '[UNK]', 'the', 'and', 'of', 'to', 'a', 'he', 'in', 'i', 'it', 'was', 'that', 'you', 'his', 'had', 'for', 'on', 'with', 'but', 'as', 'at', 'is', 'be', 'said', 'they', 'not', 'have', 'were', 'him']\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))\n",
    "print(vocabulary[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a80afb-1dd8-4c4d-827f-d5052a4c44f0",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2a709e-d15c-4a8c-8c71-bea0e8878c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    embedding_size,\n",
    "    sequence_length,\n",
    "    hidden_layer_neuron_1,\n",
    "    hidden_layer_neuron_2,\n",
    "):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(encoder)\n",
    "    model.add(layers.LSTM(hidden_layer_neuron_1, return_sequences=True))\n",
    "    model.add(layers.LSTM(hidden_layer_neuron_2))\n",
    "    model.add(layers.Dense(vocabulary_size, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f2d6a4e-a012-4ca1-b269-3730a6e066e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/Projects/DSR_Batch30/notebooks/DSR_NLP\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8a03339-51ba-4dd9-899c-1dd9bd91c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dir(model_name):\n",
    "    model_dir = \"../../models/03_sam_language_generator/\" + model_name + \"/\"\n",
    "\n",
    "    saved_dir = model_dir + \"saved/\"\n",
    "    checkpoint_dir = model_dir + \"cp/\"\n",
    "    history_dir = model_dir + \"history/\"\n",
    "\n",
    "    checkpoint_path = checkpoint_dir + \"cp-{epoch:02d}.ckpt\"\n",
    "\n",
    "    Path(saved_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(history_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return saved_dir, checkpoint_dir, history_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06e2d36-f865-4363-84ec-ee7a68e6b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_1_16_16_16_16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([session_name, \u001b[38;5;28mstr\u001b[39m(embedding_size), \u001b[38;5;28mstr\u001b[39m(sequence_length), \u001b[38;5;28mstr\u001b[39m(hidden_layer_neuron_1), \u001b[38;5;28mstr\u001b[39m(hidden_layer_neuron_2)])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layer_neuron_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layer_neuron_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     10\u001b[0m saved_dir, checkpoint_dir, history_dir \u001b[38;5;241m=\u001b[39m create_model_dir(model_name)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(embedding_size, sequence_length, hidden_layer_neuron_1, hidden_layer_neuron_2)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(encoder)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_neuron_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mLSTM(hidden_layer_neuron_2))\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(vocabulary_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-setup/lib/python3.8/site-packages/keras/engine/input_spec.py:214\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    215\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    217\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)"
     ]
    }
   ],
   "source": [
    "\n",
    "for embedding_size in embedding_sizes:\n",
    "    for sequence_length in sequence_lengths:\n",
    "        for hidden_layer_neuron_1 in hidden_layer_neurons[0]:\n",
    "            for hidden_layer_neuron_2 in hidden_layer_neurons[1]:\n",
    "                model_name = \"_\".join([session_name, str(embedding_size), str(sequence_length), str(hidden_layer_neuron_1), str(hidden_layer_neuron_2)])\n",
    "                print(model_name)\n",
    "                model = create_model(embedding_size, sequence_length, hidden_layer_neuron_1, hidden_layer_neuron_2)\n",
    "                model.summary()\n",
    "                \n",
    "                saved_dir, checkpoint_dir, history_dir = create_model_dir(model_name)\n",
    "                \n",
    "                cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath=checkpoint_dir + \"cp-{epoch:02d}.ckpt\",\n",
    "                    save_weights_only=True,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                history = model.fit(\n",
    "                    dataset,\n",
    "                    epochs=epochs,\n",
    "                    #validation_split=0.2,\n",
    "                    callbacks=[cp_callback]\n",
    "                )\n",
    "                \n",
    "                model.save(saved_dir)\n",
    "                \n",
    "                history_path_json = history_dir + model_name + \".json\"\n",
    "                json.dump(history.history, open(history_path_json, 'w'))\n",
    "                \n",
    "                history_path_csv = history_dir + model_name + \".csv\"\n",
    "                pd.DataFrame.from_dict(history.history).to_csv(history_path_csv, index=False)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1e971-70fe-471b-a851-811dae67878d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-setup",
   "language": "python",
   "name": "dsr-setup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
